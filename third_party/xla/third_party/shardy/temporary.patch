diff --git a/docs/mpmd/mpmd_sharding_propagation_passes.md b/docs/mpmd/mpmd_sharding_propagation_passes.md
index a3b51cc..3b40773 100644
--- a/docs/mpmd/mpmd_sharding_propagation_passes.md
+++ b/docs/mpmd/mpmd_sharding_propagation_passes.md
@@ -57,10 +57,3 @@ This pass is only applied to MPMD functions in global view and with a
 homogeneous topology.
 
 Precondition: all shardings are specified as op attributes and not in types.
-
-### `-mpmd-simplify-program`
-
-_Removes redundant arg/results from fragments._
-
-Simplifies a fragment or loop, its operands and results, and their
-corresponding block arguments and return values.
diff --git a/shardy/dialect/sdy/transforms/export/explicit_reshards_util.cc b/shardy/dialect/sdy/transforms/export/explicit_reshards_util.cc
index 862a2da..be8f02c 100644
--- a/shardy/dialect/sdy/transforms/export/explicit_reshards_util.cc
+++ b/shardy/dialect/sdy/transforms/export/explicit_reshards_util.cc
@@ -433,9 +433,11 @@ class FactorAxesCandidateBag {
         for (int64_t index = 1; index < factorIndices.size(); index++) {
           int64_t factorIndex = factorIndices[index];
           int64_t dependsOn = factorIndices[index - 1];
-          factorDependenciesMap
-              .try_emplace(factorIndex, shardingRule.getNumFactors())
-              .first->second.set(dependsOn);
+          if (!factorDependenciesMap.contains(factorIndex)) {
+            factorDependenciesMap.try_emplace(factorIndex,
+                                              shardingRule.getNumFactors());
+          }
+          factorDependenciesMap[factorIndex].set(dependsOn);
         }
       }
     }
diff --git a/shardy/dialect/sdy/transforms/export/insert_explicit_reshards.cc b/shardy/dialect/sdy/transforms/export/insert_explicit_reshards.cc
index dcec262..b1d7585 100644
--- a/shardy/dialect/sdy/transforms/export/insert_explicit_reshards.cc
+++ b/shardy/dialect/sdy/transforms/export/insert_explicit_reshards.cc
@@ -77,7 +77,7 @@ void insertExplicitReshardsToTargetSharding(OpOperand& opOperand,
         rewriter, operand.getLoc(), operand,
         targetSharding
             ? targetSharding
-            // Since operand and target shardings are not equivalent and
+            // Since opearand and target shardings are not equivalent and
             // `targetSharding` is empty, `operandSharding` is guaranteed to be
             // nonempty.
             : TensorShardingAttr::getFullyClosedLike(operandSharding));
@@ -327,7 +327,7 @@ void insertAllReduceOnOpIfUnreducedToReplicated(
       return sharding && !sharding.getUnreducedAxes().empty();
     };
     SDY_CHECK(!llvm::any_of(op->getOpOperands(), operandHasUnreducedAxes))
-        << "Some operands have unreduced axes but the operation has no "
+        << "Some operands has unreduced axes but the operation has no "
           "results. ";
     return;
   }
diff --git a/third_party/llvm/workspace.bzl b/third_party/llvm/workspace.bzl
index ed562d4..ba4c1a2 100644
--- a/third_party/llvm/workspace.bzl
+++ b/third_party/llvm/workspace.bzl
@@ -4,8 +4,8 @@ load("//third_party:repo.bzl", "tf_http_archive")
 
 def repo(name):
     """Imports LLVM."""
-    LLVM_COMMIT = "267fa8dd1efce0b79ebcaa804d54542c99918df2"
-    LLVM_SHA256 = "a72180219b02c46a11fa11d7ca3e5c4f57ecaa348162e010e73a59bd26623950"
+    LLVM_COMMIT = "bfee9db7857757e63b64fb4d411a264690ff711a"
+    LLVM_SHA256 = "b14cb659a35562d1fccee470d0bba41cf96363e1b576e113a3a795db9ad78e3e"
 
     tf_http_archive(
         name = name,
